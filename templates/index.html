<!DOCTYPE html>
{% load staticfiles %}
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Currency Check</title>
        <link rel="stylesheet" href="{% static 'main.css' %}" type="text/css" />
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    </head>
    <body id="index" class="home">
        <header id="banner" class="body">
            <h1><a href="#">Web Crawler<strong>Final Project for CSCI6651 - Introduction to Python</strong>
            </a></h1>
            <nav>
                <ul>
                    <li class="active"><a href="/index/">Home</a></li>
                    <li><a href="/search_currency/">Get Currency History</a></li>
                    <li><a href="/search_bank/">Get Currency</a></li>
                </ul>
            </nav>
        </header>
        <aside id="featured" class="body">
            <div id="home" class="tab-pane fade in active">
		<h1>Author</h1>
		<blockquote>
			Ang, Steven Kho<br>
			Henderson, Patrick D <br>
		</blockquote>
		<h1>Why Web Crawler</h1>
		<blockquote>
			Web Crawler can be used in various ways, one of its application is to scrap particular data from the internet based on our needs.  This interested us.  For most of the time, we are developing an application to display data from its source to the web page, and we never try to read a static data from the web page and store it back to database (or file) for more processing.  This project aimed to do that.
		</blockquote>
                <h1>Technologies we used in this application</h1>
		<ul>
		<li><h1>Web Crawler</h1></li>
	        <blockquote>
			Web Crawler, also known as Spider, is an internet not that systematically crowse the World Wide Web, typically for the purpose of Web Indexing.<br><a href="https://en.wikipedia.org/wiki/Web_crawler">https://en.wikipedia.org/wiki/Web_crawler</a><br><a href="https://scrapy.org/">https://scrapy.org/</a>
		</blockquote>

		<li><h1>Web Scrapping</h1></li>
		<blockquote>
			Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites.[1] Web scraping software may access the World Wide Web directly using the Hypertext Transfer Protocol, or through a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying, in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis.<br><a href="https://en.wikipedia.org/wiki/Web_scraping">https://en.wikipedia.org/wiki/Web_scraping</a><br>
		</blockquote>

		<li><h1>Django</h1></li>
		<blockquote>
			Django is a high-level Python Web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of Web development, so you can focus on writing your app without needing to reinvent the wheel. It is free and open source.<br><a href="https://www.djangoproject.com/">https://www.djangoproject.com</a><br>
		</blockquote>

		<li><h1>Beautifulsoup4</h1></li>
		<blockquote>
			Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.<br><a href-"https://www.crummy.com/software/BeautifulSoup/bs4/doc/">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a><br>
		</blockquote>

		<li><h1>Pandas</h1></li>
		<blockquote>
			pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.<br><a href="https://pandas.pydata.org/">https://pandas.pydata.org/</a><br>
		</blockquote>
		</ul>
            	<h1>Source Code</h1>
		<blockquote><a href="https://github.com/stevenang/WebCrawler.git">https://github.com/stevenang/WebCrawler.git</a><br>
		<h1>Folder Structure</h1>
		<ul>
			<li>Spider - Web Crawler Source Code</li>
			<li>WebCrawler - Python Source code for Web Scrapping and Django related setting</li>
			<li>WebCrawler_venv - Django Virtual Environment</li>
			<li>static - Static Files (css, images) folder</li>
			<li>templates - HTML Files</li>
		</ul>
		<blockquote>
	    </div>
        </aside>
    </body>
</html>
